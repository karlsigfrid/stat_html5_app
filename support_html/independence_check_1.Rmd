---
title: "Check for independence"
output:
  html_document:
    df_print: paged
---

If two variables are independent, then the joint distribution is the product of the marginal distributions:

$P(X=x, Y=y) = P(X=x) P(Y=y)$

### Example with independence

Lets show how this works with an example. We have the following matrix with joint probabilities:

$\begin{array}{c|c|c|c} & Y=0 & Y=1 & \\ \hline X=0 & 1/9 & 2/9 &   \\ \hline X=1 & 2/9 & 2/3 &  \\\hline &  &  & 1 \end{array}$

The sum of all the joint probabilities should be 1. Make sure that is the case.

To check whether the joint probabilities are the products of the marginal probabilities, we first need to calculate the marginal probabilities. We do this by simply adding each column and each row.

$\begin{array}{c|c|c|c} & Y=0 & Y=1 & \\ \hline X=0 & 1/9 & 2/9 & 1/3  \\ \hline X=1 & 2/9 & 4/9 & 2/3  \\\hline & 1/3  & 2/3 & 1 \end{array}$

Double check that the sums along the rows and columns are correct and that the marginal distributions of $X$ and $Y$ both sum to 1.

Now we can multiply every combination of $X$ and $Y$ and see whether the result is the same as the joint probability:

$P(X=0) \cdot P(Y=0) = \cfrac{1}{3} \cdot \cfrac{1}{3}= \cfrac{1}{9}=P(X=0, Y=0)$

$P(X=0) \cdot P(Y=1) = \cfrac{1}{3} \cdot \cfrac{2}{3}=\cfrac{2}{9}=P(X=0, Y=1)$

$P(X=1) \cdot P(Y=0) = \cfrac{2}{3} \cdot \cfrac{1}{3}=\cfrac{2}{9}=P(X=1, Y=0)$

$P(X=1) \cdot P(Y=0) = \cfrac{2}{3} \cdot \cfrac{2}{3}=\cfrac{4}{9}=P(X=1, Y=1)$

The calculations show that all four joint probabilities equal the product of the marginal distributions. This means that $X$ and $Y$ are independent.

### Example without independence

Now, look at this matrix:

$\begin{array}{c|c|c|c} & Y=0 & Y=1 &\\ \hline X=0 & 1/5 & 1/5 & 2/5   \\ \hline X=1 & 1/5 & 2/5 & 3/5  \\\hline &  2/5 &  3/5 & 1 \end{array}$

Lets see, for instance, if $P(X=0)P(Y=0)=P(X=0, Y=0)$

$P(X=0)P(Y=0)=\cfrac{2}{5} \cdot \cfrac{2}{5}=\cfrac{4}{25} \neq \cfrac{1}{5}$

The joint distribution does not equal the product of the marginal distributions. It is enough to show that this is the case for one joint probability to conclude that $X$ and $Y$ are not independent, so we are done here.

### To get you started

Now, do the independence check for this matrix:

$\begin{array}{c|c|c|c} & Y=0 & Y=1 & \\ \hline X=0 & 5/28 & 15/21 & 5/12  \\ \hline X=1 & 1/4 & 1/3 & 7/12 \\\hline & 3/7 & 4/7 & 1 \end{array}$

We will do one of the four joint probabilities here:

$P(X=0) \cdot P(Y=0) = \cfrac{5}{12} \cdot \cfrac{3}{7}= \cfrac{5}{28}=P(X=0, Y=0)$

So, the first joint probability is the same as the product of it's marginal distributions. Now it is your turn to check if that is true also for the remaining three joint distributions.

**Note:** $P(X=x, Y=y)$ can sometimes be written $f(X=x, Y=y)$, as in this exam problem. Don't worry, it's the same thing.